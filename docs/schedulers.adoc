
== Schedulers

=== `fixed_priority_scheduler`

Found in the header: `async/schedulers/priority_scheduler.hpp`

A `fixed_priority_scheduler` represents work that will be run at a certain priority.

[source,cpp]
----
using S = async::fixed_priority_scheduler<0>; // highest priority
----

NOTE: The intended use case for `fixed_priority_scheduler` is to schedule tasks
to be executed on prioritized interrupts.

A `fixed_priority_scheduler` can be given a name which is used to output debug events.
The default name is `"fixed_priority_scheduler"`.

[source,cpp]
----
auto s = async::fixed_priority_scheduler<0, "my scheduler">{};
----

The `fixed_priority_scheduler` works hand in glove with a `task_manager` that
manages tasks in priority order. A `priority_task_manager` is provided and may
be used by providing a HAL, and by specializing the `injected_task_manager`
variable template.

[source,cpp]
----
namespace {
// A HAL provides one function to enable the priority interrupt
struct hal {
    static auto schedule(async::priority_t) {}
};

// a priority task manager with 8 priority levels
using task_manager_t = async::priority_task_manager<hal, 8>;
} // namespace

// fixed_priority_scheduler will use this task_manager
template <> inline auto async::injected_task_manager<> = task_manager_t{};

// when a priority interrupt fires, the ISR executes the tasks
template <async::priority_t P>
auto interrupt_service_routine() {
  async::task_mgr::service_tasks<P>();
}
----

The result of using a `fixed_priority_scheduler` is that work is scheduled to be
run when priority interrupts fire.

[source,cpp]
----
int x{};
async::start_on(async::fixed_priority_scheduler<0>{},
          async::just_result_of([&] { x = 42; }))
| async::start_detached();

// when the interrupt fires...
async::task_mgr::service_tasks<0>();
// x is now 42
----

=== `inline_scheduler`

Found in the header: `async/schedulers/inline_scheduler.hpp`

The most basic scheduler is the `inline_scheduler`. It runs work with a regular
function call in the current execution context. It's the degenerate case as far
as concurrency goes; starting the work also completes it.

[source,cpp]
----
int x{};
auto s = async::start_on(async::inline_scheduler{},
                   async::just(42)
                 | async::then([&] (auto i) { x = i; });
async::start_detached(s);
// i is now 42
----

An `inline_scheduler` can be given a name which is used to output debug events.
The default name is `"inline_scheduler"`.

[source,cpp]
----
auto s = async::inline_scheduler<"my scheduler">{};
----

CAUTION: The `inline_scheduler` may cause stack overflows when used with certain
adaptors like xref:sender_adaptors.adoc#_repeat[`repeat`] or
xref:sender_adaptors.adoc#_retry[`retry`].

=== `runloop_scheduler`

Found in the header: `async/schedulers/runloop_scheduler.hpp`

The `runloop_scheduler` adds any work to a queue that is executed in order. It
is used as a completion scheduler inside
xref:sender_consumers.adoc#_sync_wait[`sync_wait`].

[source,cpp]
----
auto value = async::get_scheduler()
           | async::let_value([&](auto sched) {
                 return async::start_on(sched, async::just(42));
             })
           | async::sync_wait();
----

This code uses xref:sender_factories.adoc#_read_env[`get_scheduler`] to read the
scheduler provided by `sync_wait`. That `runloop_scheduler` is then used to
schedule work.

=== `thread_scheduler`

Found in the header: `async/schedulers/thread_scheduler.hpp`

The `thread_scheduler` is a basic scheduler that runs work on a newly-created
thread that is detached.

[source,cpp]
----
int x{};
auto s = async::start_on(async::thread_scheduler{},
                   async::just(42) | async::then([&] (auto i) { x = i; });
async::start_detached(s);
// without some other sync mechanism, this is risky:
// there is now a detached thread running that will update x at some point
----

A `thread_scheduler` can be given a name which is used to output debug events.
The default name is `"thread_scheduler"`.

[source,cpp]
----
auto s = async::thread_scheduler<"my scheduler">{};
----

=== `time_scheduler`

Found in the header: `async/schedulers/time_scheduler.hpp`

A `time_scheduler` represents work that will be run after a certain duration has
elapsed.

[source,cpp]
----
auto s = async::time_scheduler{10ms}; // after a duration of 10ms
----

NOTE: The intended use case for `time_scheduler` is to schedule tasks
to be executed on timer interrupts.

The `time_scheduler` works hand in glove with a `timer_manager` that
manages timer tasks. A `generic_timer_manager` is provided and may
be used by providing a HAL, and by specializing the `injected_timer_manager`
variable template.

[source,cpp]
----
namespace {
// A HAL defines a time_point type and a task type,
// and provides functions to control a timer interrupt
struct hal {
    using time_point_t = std::chrono::steady_clock::time_point;
    using task_t = async::timer_task<time_point_t>;

    static auto enable() -> void;
    static auto enable(auto duration) -> time_point_t; // optional
    static auto disable() -> void;
    static auto set_event_time(time_point_t tp) -> void;
    static auto now() -> time_point_t;
};

// use the generic timer manager
using timer_manager_t = async::generic_timer_manager<hal>;
} // namespace

// tell the library how to infer a time point type from a duration type by
// specializing time_point_for
template <typename Rep, typename Period>
struct async::timer_mgr::time_point_for<std::chrono::duration<Rep, Period>> {
    using type = hal::time_point_t;
};

// time_scheduler will use this timer_manager
template <> inline auto async::injected_timer_manager<> = timer_manager_t{};

// when a timer interrupt fires, the ISR executes the next task
auto timer_interrupt_service_routine() {
  async::timer_mgr::service_task();
}
----

NOTE: `async::timer_task` is a generic provided task type that is parameterized
with the time point type.

NOTE: If `async::timer_mgr::time_point_for` is left unspecialized, the library
will assume that a duration type and time_point type are the same.

The result of using a `time_scheduler` is that work is scheduled to be
run when a timer interrupt fires.

[source,cpp]
----
int x{};
async::start_on(async::time_scheduler{10ms},
          async::just_result_of([&] { x = 42; }))
| async::start_detached();

// when the interrupt fires...
async::timer_mgr::service_task();
// x is now 42
----

It is also possible to create a `time_scheduler` without specifying a duration:
in this case it will use the connect receiver's environment to obtain an
`expiration_provider` in order to compute the expiration time. The xref:sender_adaptors.adoc#_periodic[`periodic`]
adapter uses such an environment to achieve drift-free periodic scheduling.

==== HAL interaction

The various HAL functions are called as follows:

On queueing the first task (consuming a `time_scheduler` sender), _either_:

 - `enable()`
 - `now()`
 - `set_event_time(time_point)`

_or_ (if this function is optionally available):

 - `enable(duration)`

NOTE: The second case allows the HAL to fuse enabling and setting the expiry
time, if it's possible to do that more efficiently. The return value should be
equivalent to `now() + duration`. The type of `duration` is equivalent to the
type obtained by subtracting two `time_point_t`â€‹s.

On queueing a new task which _is not_ the next to expire:

 - `now()`

On queueing a new task which _is_ the next to expire:

 - `now()`
 - `set_event_time(time_point)`

On processing a task (not the last) with `service_task()`:

 - `set_event_time(time_point)`

On processing the last currently queued task with `service_task()`:

 - `disable()`

Note that interaction with the HAL starts with a single `enable()` call, and
ends with a single `disable()` call. This means that when `enable()` is called,
the HAL is free to reset its timer. And when `disable()` is called, the HAL is
free to disable the timer or even remove power. In between `enable()` and
`disable()` calls, the timer should be free-running. It should not be reset
while running: this will invalidate timing data in the task queue.

NOTE: `enable()` is called to start the timer, and `disable()` is called when no
more timers are active. When one timer expires and another in the queue is set,
`enable()` is _not_ called again for the second timer.

NOTE: `enable()` is called from the context which consumes the `time_scheduler`
sender to kick off the work. `disable()` is called from the timer interrupt
context that processes the last task in the queue. And in general, each call to
`set_event_time()` to schedule the next timer task executes in the previous
task's timer interrupt context.

==== time domains

A given system may have several independent timers. For that reason, a
`time_scheduler` and an `injected_timer_manager` may be associated with a
domain. A domain is typically just a tag type.

[source,cpp]
----
namespace {
// a tag type identifying an alternative timer domain
struct alt_domain;

// A HAL that interacts with different registers
// for that alternative timer domain
struct alt_domain_hal { ... };

// the generic timer manager is still fine for the alt_domain
using alt_timer_manager_t = async::generic_timer_manager<alt_domain_hal>;
} // namespace

// a time_scheduler for the alt domain will use the alt timer_manager
template <> inline auto async::injected_timer_manager<alt_domain> = alt_timer_manager_t{};

// to make it easy to create schedulers for that domain, use a factory
auto sched_factory = async::time_scheduler_factory<alt_domain>;
auto sched = sched_factory(10ms);

int x{};
auto s = async::start_on(sched,
                   async::just(42) | async::then([&] (auto i) { x = i; });
async::start_detached(s);

// after 10ms, the alt domain interrupt will
// call service_task for the alt_domain...
auto alt_timer_interrupt_service_routine() {
  async::timer_mgr::service_task<alt_domain>();
}

// and now x is 42
----

A `time_scheduler_factory` can be given a name that it passes on to the
schedulers it creates, and which is used to output debug events. The default
name is `"time_scheduler"`.

[source,cpp]
----
auto sched_factory = async::time_scheduler_factory<alt_domain, "my scheduler">;
----

=== `trigger_scheduler`

Found in the header: `async/schedulers/trigger_scheduler.hpp`

A `trigger_scheduler` represents work that will be run on a named user-defined
trigger, like a specific interrupt service routine.

[source,cpp]
----
using S = async::trigger_scheduler<"name">;
----

The `trigger_scheduler` works hand in glove with a `trigger_manager` that
manages tasks in queued order. The action is very similar to that of the
`priority_task_manager`, but instead of dealing with multiple priorities, tasks
for a given trigger are identified with the trigger name.

[source,cpp]
----
// when an interrupt fires, the ISR executes the tasks for the trigger
auto interrupt_service_routine() {
  async::triggers<"name">.run();
}
----

The result of using a `trigger_scheduler` is that work is scheduled to be
run when such an interrupt fires and runs the ISR.

[source,cpp]
----
int x{};
async::start_on(async::trigger_scheduler<"name">{},
          async::just_result_of([&] { x = 42; }))
| async::start_detached();

// when the interrupt fires...
async::triggers<"name">.run();
// x is now 42
----

A `trigger_scheduler` can also be triggered with arguments, which must be
specified as template arguments, and supplied using `run_triggers`:

[source,cpp]
----
int x{};
async::trigger_scheduler<"name", int>{}.schedule()
  | async::then([&] (auto i) { x = i; })
  | async::start_detached();

// when the interrupt fires...
async::run_triggers<"name">(42);
// x is now 42
----

NOTE: It is possible to use a `trigger_scheduler` that takes arguments as a
"normal" scheduler, i.e. functions like `start_on` will work; however the
arguments passed to `run_triggers` will be discarded when used with constructs
like `start_on(trigger_scheduler<"name", int>{}, just(42))`.
